{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gross-situation",
   "metadata": {},
   "source": [
    "### Housekeeping code snippets\n",
    "imports, and code to download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time\n",
    "import fastbook\n",
    "from tqdm import tqdm\n",
    "# fastbook.setup_book()\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "key = os.environ.get('AZURE_SEARCH_KEY', 'XXX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_images_bing(key, term, min_sz=128, max_images=150, offset=0):\n",
    "    limit = 150\n",
    "    left = max_images\n",
    "    li = []\n",
    "    while left > 0:\n",
    "        params = dict(q=term, count=left, min_height=min_sz, min_width=min_sz, offset=offset)\n",
    "        search_url = \"https://api.bing.microsoft.com/v7.0/images/search\"\n",
    "        response = requests.get(search_url, headers={\"Ocp-Apim-Subscription-Key\":key}, params=params)\n",
    "        response.raise_for_status()\n",
    "        left = max_images - limit\n",
    "        max_images = left\n",
    "        offset += limit\n",
    "        li += list(response.json()['value'])\n",
    "    return L(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download images\n",
    "inst_types = ['ukulele', 'acoustic guitar', 'electric guitar', \"4 string bass guitar\"]\n",
    "path = Path('instruments')\n",
    "\n",
    "# 2-fold test set\n",
    "# path = Path('instruments_test') --> 20 images \n",
    "# path = Path('instruments_test_1') --> 20 images\n",
    "\n",
    "if not path.exists():\n",
    "    path.mkdir()\n",
    "    for o in tqdm(inst_types):\n",
    "        dest = (path/o)\n",
    "        dest.mkdir(exist_ok=True)\n",
    "        results = search_images_bing(key, f'{o}', max_images = 150)\n",
    "        download_images(dest, urls=results.attrgot('contentUrl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-corrections",
   "metadata": {},
   "source": [
    "### Training with multiple hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import torch\n",
    "import wandb\n",
    "import gc\n",
    "import requests, time\n",
    "import fastbook\n",
    "from tqdm import tqdm\n",
    "fastbook.setup_book()\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *\n",
    "from fastai.callback.wandb import *\n",
    "\n",
    "size = [(224, 64), (336, 16), (448, 16)]\n",
    "min_scale = [0.2]\n",
    "max_scale = [0.5]\n",
    "min_zoom = [1.0, 1.1, 1.2, 1.3]\n",
    "max_zoom = [1.3]\n",
    "\n",
    "\n",
    "def verify_images(fns):\n",
    "    failed = []\n",
    "    for f in fns:\n",
    "        if not verify_image(f):\n",
    "            failed.append(f)\n",
    "    return L(failed)\n",
    "\n",
    "def validate(path, classes, learn):\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for o in classes:\n",
    "        dest = (path/o)\n",
    "        for i in get_image_files(dest):\n",
    "            count += 1\n",
    "            pred = learn.predict(i)\n",
    "            if o == pred[0]:\n",
    "                correct += 1\n",
    "    return correct/count\n",
    "\n",
    "def train_and_validate(path, test_path, classes, size, bs, min_scale, max_scale, min_zoom, max_zoom):\n",
    "    train_db = DataBlock(blocks=(ImageBlock, CategoryBlock), \n",
    "                  get_items = get_image_files,\n",
    "                  splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "                  get_y = parent_label,\n",
    "                  item_tfms=RandomResizedCrop(size, min_scale=min_scale, max_scale=max_scale),\n",
    "                  batch_tfms = aug_transforms(min_zoom=min_zoom, max_zoom=max_zoom))\n",
    "    dls = train_db.dataloaders(path, bs=bs)\n",
    "    fname= f'{size}_{min_zoom}_{max_zoom}'\n",
    "    learn = cnn_learner(dls, resnet18, metrics=error_rate, cbs=[SaveModelCallback(fname=fname)])\n",
    "    learn.fine_tune(0)\n",
    "    accuracy = validate(test_path, classes, learn)\n",
    "    if not os.path.exists('models_exp'):\n",
    "        os.makedirs('models_exp')\n",
    "    learn.export(f'models_exp/{fname}.pkl')\n",
    "    del dls, train_db, learn \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return accuracy\n",
    "\n",
    "results = []\n",
    "trials = list(product(size, min_scale, max_scale, min_zoom, max_zoom))\n",
    "path = Path('instruments')\n",
    "test_path = Path('instruments_test')\n",
    "failed = verify_images(get_image_files(path))\n",
    "failed.map(Path.unlink)\n",
    "failed = verify_images(get_image_files(test_path))\n",
    "failed.map(Path.unlink)\n",
    "\n",
    "classes = 'acoustic guitar', 'electric guitar', 'ukulele', '4 string bass guitar' \n",
    "for trial in trials:\n",
    "    si, min_scale, max_scale, min_zoom, max_zoom = trial\n",
    "    size, bs = si\n",
    "    result = train_and_validate(path, test_path, classes, size, bs, min_scale, max_scale, min_zoom, max_zoom)\n",
    "    results.append((trial, result))\n",
    "    print(trial, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-palmer",
   "metadata": {},
   "source": [
    "### Testing the models performance on 2 unseen test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-stick",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = Path('models_exp')\n",
    "test_path = [Path('instruments_test'), Path('instruments_test_1')] \n",
    "# test_path = Path('instruments_test')\n",
    "classes = 'acoustic guitar', 'electric guitar', 'ukulele', '4 string bass guitar' \n",
    "\n",
    "results_all = []\n",
    "for model in path.ls(file_exts='.pkl'):\n",
    "    learn = None \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    learn = load_learner(model)\n",
    "    accuracy = []\n",
    "    for fold in test_path:\n",
    "        accuracy.append(validate(fold, classes, learn))\n",
    "    results_all.append((model, accuracy))\n",
    "    learn = None\n",
    "    del learn \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "print(results_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(results_all, key= lambda x: x[1][1])[::-1][:6]\n",
    "\n",
    "best_models = [i[0] for i in sorted(results_all, key= lambda x: x[1][1])[::-1][:6]]\n",
    "# best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-mobile",
   "metadata": {},
   "source": [
    "### Ensemble from the best 6 models\n",
    "Voting from each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-street",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def validate_ensemble_models(best_models):\n",
    "    models = [(model, load_learner(model)) for model in best_models]\n",
    "    test_path = [Path('instruments_test'), Path('instruments_test_1')] \n",
    "    classes = 'acoustic guitar', 'electric guitar', 'ukulele', '4 string bass guitar'\n",
    "    count = 0\n",
    "    correct = 0\n",
    "    wrong_preds = []\n",
    "    \n",
    "    acc = []\n",
    "    for model in models:\n",
    "        accuracy = 0\n",
    "        for fold in test_path:\n",
    "            accuracy += validate(fold, classes, model[1])\n",
    "        accuracy /= 2\n",
    "        acc.append((model[0], accuracy))\n",
    "        \n",
    "    for o in classes:\n",
    "        for fold in test_path:\n",
    "            dest = (fold/o)\n",
    "            for i in get_image_files(dest):\n",
    "                count += 1\n",
    "                pred = [learn[1].predict(i)[0] for learn in models]\n",
    "                pred_class = Counter(pred).most_common(1)[0][0]\n",
    "                if o == pred_class:\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    print(dest, i, pred_class, Counter(pred).most_common(1))\n",
    "                    wrong_preds.append((dest, i, pred_class))\n",
    "                    \n",
    "    return correct/count, wrong_preds, acc\n",
    "a, w, acc = validate_ensemble_models(best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, w, acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
